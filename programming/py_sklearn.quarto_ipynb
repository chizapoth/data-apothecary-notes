{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Cheatsheet: Scikit-learn\"\n",
        "description: |\n",
        "  Refer to the jupyter notebook for rendered code.\n",
        "author: \"Chi Zhang\"\n",
        "date: \"2025-02-26\"\n",
        "categories: [Python]\n",
        "sidebar: false\n",
        "code-block-bg: true\n",
        "code-block-border-left: true\n",
        "jupyter: python3\n",
        "format: \n",
        "  html:\n",
        "    toc: true\n",
        "    toc-depth: 3\n",
        "    code-fold: false\n",
        "    code-tools: false\n",
        "    code-annotations: select\n",
        "---\n",
        "\n",
        "### Load the usual libraries \n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "```\n",
        "\n",
        "### Data exploration \n",
        "\n",
        "```python\n",
        "data.head()\n",
        "data.describe()\n",
        "data.shape\n",
        "data.columns # check colnames\n",
        "```\n",
        "\n",
        "Visualize data\n",
        "\n",
        "```python\n",
        "sns.histplot(data.variable)\n",
        "sns.scatterplot(x = data.var1, y = data.var2)\n",
        "# pair plot for low dimension data\n",
        "sns.pairplot(data, hue = 'categorical_var')\n",
        "```\n",
        "\n",
        "## Feature engineering\n",
        "\n",
        "```python\n",
        "# split the response and explanatory\n",
        "X = data.drop('response', axis = 1)\n",
        "y = data['response']\n",
        "```\n",
        "\n",
        "Train test split\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "Xtrain, Xtest, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
        "```\n",
        "\n",
        "Can check the size of the data using `Xtrain.shape`\n",
        "\n",
        "\n",
        "Cross validation \n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import cross_val_score\n",
        "cvs = cross_val_score(model, Xtrain, y_train, cv = 10)\n",
        "```\n",
        "\n",
        "\n",
        "## Fit ML model and predictions\n",
        "\n",
        "General workflow\n",
        "\n",
        "```python\n",
        "from sklearn.MODEL import CLASSIFIER\n",
        "YOUR_MODEL = CLASSIFIER(PARA)\n",
        "YOUR_MODEL.fit(Xtrain, ytrain)\n",
        "\n",
        "# predict class\n",
        "YOUR_MODEL.predict(Xtest)\n",
        "```\n",
        "\n",
        "Common parameters to tune\n",
        "\n",
        "* `C`: float, default is 1. Inverse of regularization strength. Must be a positive float. Smaller values specify stronger regularization\n",
        "* `random_state`: integer\n",
        "* `solver`: depends on the classifier. Should check the docs.\n",
        "\n",
        "\n",
        "### Logistic regression\n",
        "\n",
        "[Scikit-learn doc: Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression(C=C, penalty=\"l2\", solver=\"saga\", max_iter=10000)\n",
        "```\n",
        "\n",
        "\n",
        "Usually for two classes, but also common in multiclass problems, such as `OneVsRestClassifier`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Decision tree and random forest\n",
        "\n",
        "They can work on more than two classes, as well as regression.\n",
        "\n",
        "For decision tree, probability prediction isn't available.\n",
        "\n",
        "```python\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree = DecisionTreeClassifier().fit(Xtrain, ytrain)\n",
        "\n",
        "# predict class\n",
        "tree.predict(Xtest)\n",
        "```\n",
        "\n",
        "\n",
        "Random forest\n",
        "\n",
        "```python\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "forest = RandomForestClassifier(max_depth=3, random_state=42)\n",
        "forest.fit(Xtrain, ytrain)\n",
        "\n",
        "# predict class\n",
        "forest.predict(Xtest)\n",
        "\n",
        "# predict probability\n",
        "forest.predict_proba(Xtest)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### Naive Bayes\n",
        "\n",
        "```python\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB()\n",
        "model.fit(Xtrain, y_train)\n",
        "\n",
        "# can also be written as model = GaussianNB().fit(X,y)\n",
        "y_model = model.predict(Xtest)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## Performance\n",
        "\n",
        "### Class accuracy\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_model)\n",
        "# can also try to compare the results manually\n",
        "np.sum(y_test == y_model) \n",
        "```\n",
        "\n",
        "\n",
        "### Probabilities\n",
        "\n",
        "Carry out row-wise summation, see if they sum up to 1\n",
        "\n",
        "```python\n",
        "rf_prob.sum(axis = 1)\n",
        "```\n",
        "\n",
        "### ROC curve\n"
      ],
      "id": "6abbb0a8"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/chizhang/.pyenv/versions/3.12.7/envs/mypydev312/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}